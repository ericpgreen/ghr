[
["index.html", "Global Health Research: Design and Methods Preface About this Book Organization Icons Acknowledgements Colophon", " Global Health Research: Design and Methods Eric P. Green 2016-08-26 Preface Does the world really need another book about research methods? I think so. But I spent a fair amount of time writing down the ideas in this book, so I’m biased. But here’s my rationale. I went to graduate school for clinical psychology, and my classmates and I read all of the classic psychology texts on research design and methods. Books like “Experimental and Quasi-Experimental Designs for Generalized Causal Inference” by Shadish, Cook, and Campbell (2003). I still remember staying up late trying to memorize all of the different threats to internal validity outlined by Donald Campbell and colleagues. Meanwhile, across campus, my econ colleagues were reading the ideas of another Donald—Donald Rubin and what is now known as Rubin’s causal model. But I didn’t know this at the time. When I set off for Uganda in 2007, determined to learn more about this field called global health, I met some of these mini Donald Rubin’s in the wild. I tried communicating with them, but they had a strange dialect that I couldn’t quite understand. And they did not understand me and my Campbellian drawl. We were usually trying to say the same thing, just in the language of our peoples. But I couldn’t put all of the blame on the economists and the disciplinary gap between us. There was a lot I didn’t know that went far beyond differences in jargon. I was a psychologist trained in clinical research, and nearly every applied example I read about came from the U.S. or Europe. The young field of global mental health was still an infant when I was in school. The first Lancet series on global mental health that really put the field on the map was published in September 2007 as I was getting on a plane to fly back home. I really knew nothing about global health. Fortunately, students entering university today have many more opportunities to learn about global health through interdisciplinary studies. Duke University launched the first liberal arts global health major in the U.S. in 2013, and other universities have followed suit. The Duke program is unique because it requires global health students to co-major in another discipline, such as biology, economics, psychology, or public policy. I started teaching at Duke around the time the new co-major started, and I found myself in the position of needing to pick a textbook for a course called “Research Methods in Global Health”. I reviewed a lot of excellent books that covered the basics, but none integrated examples from the very diverse and interdisciplinary field that is global health. I saw this as a real limitation. So I decided to write my own book. About this Book A guiding principle of this book is that a student of global health needs to be a student of medicine, biology, statistics, economics, psychology, public policy, and the list goes on. Just take a topic like malaria. A literature search will return articles about the spread of the disease (epidemiology), the impact of illness on future productivity (economics), the merits of free or subsidized bed nets (public policy), mosquito habitats (ecology), the efficacy of vaccines to prevent the disease (medicine and statistics), rapid diagnostic tests (biomedical engineering), the adoption and use of bed nets (psychology), and many others. No one book or author could ever hope to provide full disciplinary coverage of even one topic like malaria, so my goal was much more modest. I wanted to create a resource that would teach the basics of research design and methods by exposing readers to real world global health examples from different disciplines. Another guiding principle is openness. Whenever possible, the examples come from open access sources. Every reader should be able to access 90% of the references in this book. Organization The book is organized as follows. One objective of my course on global health research—and thus this book—is to make students better consumers of research. I wrote the first three chapters with this end in mind. Chapter 1 reviews the fundamentals of scientific research, but with a global health spin. In Chapter 2, you’ll learn how to search the literature for existing evidence. Better yet, you’ll learn to let someone else do that for you in the form of a systematic review or meta-analysis. You’ll also learn how to begin asking your own research questions. Chapter 3 on critical appraisal will teach you how to read and evaluate scientific evidence. One of the most important claims you’ll need to assess as a consumer of research is causality. Chapter 4 examines strategies for building up causal arguments. A second objective of my course is to give students the tools they need to begin careers as producers of research. The next few chapters lay this foundation. Chapter 5 gives you practical advice on developing a theory of change to guide program development, monitoring, and evaluation. It also helps to organize your approach to measurement, the topic of Chapter 6. This chapter explains how to define the measurement of your key study outcomes and covers fundamental psychometric concepts such as reliability and validity. In Chapter 7, you’ll learn strategies for determining how many research subjects you should recruit and methods for selecting them. The next two chapters introduce methods for collecting data. Chapter 8 covers quantitative methods, and Chapter 9 covers qualitative and approaches to mixing qualitative and quantitative methods. With the basics out of the way, we turn to designs that you can use to answer your research questions. Chapters 10 and 11 cover non-experimental designs. Chapter 10 focuses on the observational designs you typically find in epidemiology (e.g., cohort, case-control) and psychology (e.g., correlational). Chapter 11 introduces several “quasi-experimental” designs that manipulate a cause that comes before an effect, but without the benefit of randomization, the topic of Chapter 12. All of these chapters will refer back to the foundation in cause and effect we set in Chapter 4. The book concludes with several chapters to help you use your new knowledge to make an impact. In Chapter 13 you will learn how to prepare a study protocol. Chapter 14 will introduce you to the publication process and other opportunities for disseminating your work, such as professional conferences. Chapter 15 pushes you to think beyond your study results to make an impact on policy and practice. One limitation of this book is that it does not teach statistics. Statistical concepts are discussed throughout, but not in great detail. Every statistician will tell you that you need to think through your analysis at the study design stage. Listen to this advice. While this book will not give you the technical tools you need to plan your analysis, I hope you will come away with more appreciation for the gaps in your knowledge that you need to fill with further study. A great resource for learning applied statistics is OpenIntro Stats. If you are fortunate to be at a university with an applied statistics department, chances are you could get excellent consultation on your study protocol. This book WILL prepare you to narrow your options and have a smart conversation about how to meet your study objectives. Icons I’ve sprinkled several types of asides throughout the book. If you are a student enrolled in my course, I recommend that you actually read them. Everyone else can flip the page and feel productive. Help piecing together the global health puzzle Extended discussion of a special topic Tips Videos Application exercises Acknowledgements I’d like to thank some folks for their helpful feedback at various points throughout my writing process. My graduate student teaching assistants, Kaitlin Saxton, Kathleen Perry, and Jenae Logan, read and commented on the initial drafts. This could not have been fun, so thanks! Thanks to Duke librarians Megan Von Isenburg and Hannah Rozear for setting me straight on literature searches. I still have a lot to learn! Liz Turner, biostatistican extraordinaire, kept me from making too many mistakes on technical details here and there. I’d also like to thank students in my undergraduate and graduate global health research courses for test driving the book before all the parts were in place. Your feedback was [placeholder], and the book would have been [placeholder] without you. Special shoutout to the following students for sharing written feedback: Kelsey Sumner, Karly Gregory, Qian Yudong, and Christina Schmidt. Despite everyone’s best efforts to help me catch mistakes, I’m certain errors remain in the book. My bad. Colophon This book is a work in progress. If you find errors (gasp!), please create an issue on Github, email me, or shame me on Twitter (@ericpgreen). I’m writing the book in R Markdown within RStudio. The bookdown package from the makers of RStudio does most of the heavy lifting to compile the book. The source code for the book is available on Github. References "],
["science.html", "1 Research 101 1.1 Scientific Research 1.2 The Fundamentals Test Yourself", " 1 Research 101 Believe it or not, you already know the basics of the research process. You probably have a yellowing, tri-fold piece of cardboard tucked in the back of the closet in your parents’ house that would prove me right. Just like Jimmy.1 Figure 1.1: What you see here is the scientific method in action. Jimmy asked a question, made a hypothesis, collected and analyzed data, and ultimately, made some conclusions based on the results. Science!. Source: http://bit.ly/1HbluM4 Even if you have not been as productive as Jimmy, I’m certain that you’ve had years of practice consuming research. We’re exposed to popular press accounts of research every day on TV, the radio, and the internet. Much of it might be wrong—“new study proves that eating chocolate prevents all cancer”—but it’s a start. So it’s a safe bet that just about every reader has some foundation to build upon. The goal of this chapter, therefore, is to re-introduce familiar concepts about scientific research from a global health perspective. We’ll come back to these fundamentals throughout the book and explore them in more detail. By the end you’ll be ready to move your work from primary school cafeteria to academic conferences, policy debates, and real world program design and delivery. 1.1 Scientific Research Let’s start with what we mean by “scientific research”. King et al. (1994) offer a useful definition in their book, “Designing Social Inquiry”. They point to several main characteristics: The goal is inference The procedures are public The conclusions are uncertain 1.1.1 All about inference By stating that the goal of scientific research is inference, we mean that science goes beyond the collection of facts. You’ve probably seen the word inference used in several different contexts in your global health studies. At the most basic level, when we talk about inference, we are referring to the process of making conclusions about some unobserved or unmeasured phenomenon based on our direct observations of the world. We use what we know to infer something about the things we don’t know. This process can be deductive or inductive. In deductive reasoning, we start from general theories, make hypotheses, collect data, and make conclusions based on the data. Inductive reasoning flows the other direction, from specific observations to the generation of hypotheses and theories. Remember it this way: if you are testing a specific hypothesis, you are using deductive reasoning. If you are starting with your observations and making more general statements, then you are using inductive reasoning. To say that quantitative research is deductive and qualitative research is inductive is not quite right, but it’s often true.2 For instance, Singla et al. (2015) report the results of a cluster randomized trial of a parenting intervention in rural Uganda. This study used quantitative methods; the primary outcomes of this study were cognitive and receptive language development of the children of participating caregivers measured with the Bayley Scales of Infant Development. The authors hypothesized that the intervention would improve child development. As you can see in the following table from the article, the program increased cognitive and receptive language scores, but did not have an effect on height-for-age, thus partially supporting the hypothesis. Figure 1.2: Source: Singla et al. (2015), http://bit.ly/1UcVtoZ Later in the book we’ll get into the nitty gritty details of how you read and interpret results like you see here. For now, let’s focus on the approach to reasoning. Singla et al. is an example of deductive reasoning. The authors started with a hypothesis, collected quantitative data (i.e., scores on a measure called the Bayley), and inferred something about the impact of the intervention.3 We can contrast the Singla et al. trial with a qualitative study by Sahoo et al. (2015) that exemplifies inductive reasoning. Sahoo and colleagues used a grounded theory approach to conduct and analyze interviews with 56 women in Odisha, India about their sources of stress and sanitation practices.4 This study is an example of inductive reasoning because the authors started with the data—their observations—looked for themes and patterns, and came to some conclusions about the nature of sanitation-related stress.5 One result of this work was a conceptual framework for thinking about sanitation-related psychosocial stress, as shown below.6 Figure 1.3: Source: Sahoo et al. (2015), http://bit.ly/1JB6nSs The point to take away about inference is that, regardless of the approach to reasoning, the goal of scientific research is to use what we observe to make conclusions about what we do not observe directly. This is sometimes referred to as empiricism, and our systematic observations as empirical evidence. Empiricism is at the heart of scientific research. 1.1.2 Research as a public act Scientific research uses public methods that can be examined and replicated. Replication is a core principle of scientific research. No one study rules the day. If the results of your study are robust, another research group should be able to follow your methods and replicate the findings. When findings are replicated, we all have more confidence in the results. Replications are relatively rare, however. For one, there are often few resources for replicating studies, especially when it comes to big field experiments. Second, journal space is limited (especially if there is still a print version) and peer review takes a lot of resources. Journals want to use their space and resources to publish novel ideas (ironically, novelty can sometimes mean small effects with a lot of noise that might fail to replicate). Without the promise of a publication, researchers have little incentive to spend time and money trying to replicate published findings. Publications are a key criterion for tenure and promotion in academia, so many researchers don’t waste their efforts on studies that won’t get published. What happens when replications are attempted? Well, that’s a topic for a later chapter. The short answer is bitterness. Replicators grab more headlines when they “debunk” findings, and the original authors almost invariably call into question the quality of the replication. Just see #wormwars to learn what happened when a famous de-worming study was re-examined. Or Google social psychology and priming. Yikes! A separate but related issue is reproducibility, the ability to generate a study’s findings given the original dataset and sometimes the original analysis code. Think irreproducible findings are rare? Think again. The Quarterly Journal of Political Science found that slightly more than half of their published empirical papers subjected to review had results that could not be replicated with the author’s own code. The positive part of this story is that it’s becoming more common for authors to share their data and analysis code. This has been standard practice in economics for some time, but the idea is revolutionary in medicine and public health. We’ll explore why this is so important and easier than ever to do. 1.1.3 Living with uncertainty Every method has limitations, every measurement has error, and every model is wrong to some extent. In short, research is an imperfect process. Sometimes researchers make outright mistakes. These mistakes may or may not be detected and corrected in the peer review process, or during post-publication review if authors share their data and analysis code. Other findings are free of obvious mistakes, but fail to be replicated, and over time run counter to a growing body of literature that points in the other direction. In this way science is said to be self-correcting. We’ll discuss how this ideal can fall short in the face of challenges like publication bias, but the point here is to get comfortable in the short term with the idea of uncertainty. A good example of uncertainty comes from the estimation of maternal mortality. Hogan et al. (2010) published estimates for 181 countries. Some countries like the United States have vast amounts of data; vital registries that attempt to track all births and deaths. Countries with vital registries struggle with changing definitions over time, but the uncertainty interval around their estimates is typically tight, as shown in the figure below from the Hogan et al.’s supplementary webappendix, because there is a lot of good data. Figure 1.4: Source: Hogan et al. (2010), http://bit.ly/1JBCelO In many low-income countries the situation is very different. Here is the estimate and uncertainly interval for maternal mortality in Afghanistan. There are only four data points! No wonder the uncertainty interval is so great.7 Figure 1.5: Source: Hogan et al. (2010), http://bit.ly/1JBCelO So how many women die during pregnancy or within 42 days of delivery? The same research group that published Hogan et al., the Institute for Health Metrics and Evaluation, estimated that there were 292,982 maternal deaths globally in 2013, with a 95% uncertainty interval ranging from 261,017 to 327,792; that’s a range of 66,775 for everyone who struggles with mental math (Kassebaum et al. 2014). This might seem like a lot, but remember that we’re talking about global statistics for a world population of more than 7 billion people.8 The takeaway message is that there is uncertainty in everything. Don’t take any single estimate as the “Truth”. Instead, try to learn about the origin of estimates and recognize the limitations of what we know. 1.2 The Fundamentals Before we get too far along, we need to establish a common understanding of some fundamental concepts and terms. We’ll do so in the context of research on malaria.9 1.2.1 The nature of research Research can be classified as basic or applied. Basic research—or “pure” research—is the pursuit of fundamental knowledge of phenomena. An example would be the bench science to understand the parasitic life cycle and how parasites interact with humans at different stages. Basic research can be contrasted with applied research which is focused on specific problems or applications. For instance, an applied research question is how to increase the coverage and use of bed nets that prevent malaria transmission. Applied science takes many different forms, including clinical research. Clinical research is a broad field that encompasses patient-oriented research, epidemiological and behavioral studies, and outcomes research and health services research.10 Basic research is the foundation of clinical research. Clinical trials One type of clinical research is a clinical trial. Drugs and vaccines have to pass through different phases of clinical trials before regulatory bodies will approve their use with humans: Preclinical research Phase I Phase II Phase III Phase IV Let’s take the development of a vaccine for malaria as an example of the clinical trial life-cycle. A vaccine candidate called RTS,S, or Mosquirix™, recently made news for getting one step closer to becoming a licensed vaccine after a successful Phase III trial. This moment was more than 30 years in the making. Development of RTS,S began in 1984 through a partnership between the pharmaceutical company GSK and the Walter Reed Army Institute of Research. The vaccine candidate was created in 1987 and entered preclinical research. During the pre-clinical phase, testing is performed in non-human subjects with the goal of collecting data on how well the vaccine works (efficacy), how much damage it can do to an organism (toxicity), and how it is affected by the body (pharmacokinetics). Clinical research on humans began in 1992. To obtain regulatory approval, the vaccine had to complete three phases of testing. Doherty et al. (1999) conducted a Phase I safety and immunogenicity trial with 20 adults in The Gambia in 1997. This small sample size is typical of Phase I trials where the objective is usually to find a safe dosing range and look for side effects. The authors reported that the vaccine did not have any significant toxicity but did produce the expected antibodies. Several Phase II studies conducted over a decade (Phase IIa and Phase IIb) demonstrated efficacy of the vaccine against several endpoints (a.k.a. outcomes) (Moorthy and Ballou 2009). A Phase IIb trial began in Mozambique in 2003 with more than 2,000 children aged 1 to 4 (Alonso et al. 2004). Children were randomly assigned to receive three doses of RTS,S or a control vaccine. At 6-months, the prevalence of malaria was 37% lower in the treatment group compared to the control group. A follow-up study with 214 infants also showed partial protection (Aponte et al. 2007). This was an important proof-of-concept. Final results of a large Phase III trial with more than 15,000 infants and young children in seven African countries were published in The Lancet in 2015 (RTS,S Clinical Trials Partnership 2015). Children in the study were randomly assigned to 1 of 3 arms: 3 doses of RTS,S and a booster dose at month 20; 3 doses of RTS,S and a booster dose of a comparator vaccine at month 20; or 4 doses of a comparator vaccine. The study reported that RTS,S reduced clinical malaria cases by 28% and 18% among young children and infants, respectively, over a 3 to 4 year period. This is the goal of a Phase III trial—to show that a treatment is efficacious. On the basis of these results, the European Medicines Agency issued a “European scientific opinion”, which could help inform the decision of the WHO and African national regulatory authorities. If RTS,S is approved for use and eventually hits the market, researchers will likely conduct Phase IV trials to evaluate the vaccine’s long-term effects. This will not be the end for research on RTS,S, however. The vaccine may be efficacious, but that does not mean it will be easy or cost-effective to deliver at scale to millions. Studies that assess how to best get efficacious treatments to the people who need it most fall under the domain of implementation science. There are many stumbling blocks from getting interventions from “bench to bedside”, so to speak. Practitioners of translational research point to four key bottlenecks: T1: translation from basic science to clinical research T2: translation from early clinical trials to Phase III trials and beyond with larger patient populations T3: translation from efficacy (Phase III) to real-world effectiveness—the domain of implementation science T4: translation from evidence about delivery at scale to new policy Behavioral research (e.g., development and evaluation of parenting interventions) does not follow the same exact phases of vaccine and drug development, but the broad principles are the same. Monitoring and evaluation Another arena of applied work in global health is monitoring and evaluation, or M&amp;E. Let’s start with the “E”, program evaluation. In the U.S., program evaluation became commonplace by the end of the 1950s and grew dramatically in the 1960s as the federal government expanded and introduced new social programs. Lawmakers wanted accountability, and the evaluation of social programs took off (Rossi, Lipsey, and Freeman 2003). But is program evaluation considered research? Methods giant Donald Campbell thought so (Campbell 1969): The United States and other modern nations should be ready for an experimental approach to social reform, an approach in which we try out new programs designed to cure specific problems, in which we learn whether or not these programs are effective, and in which we retain, imitate, modify or discard them on the basis of their effectiveness on the multiple imperfect criteria available. Campbell had an outsized impact on the field. It’s no surprise that an organization dedicated to synthesizing the best available evidence on social interventions, the Campbell Collaboration, bears his name. A good candidate for Donald Campbell’s successor is French economist and MIT researcher Esther Duflo. Together with Abhijit Banerjee and Sendhil Mullainathan, she co-founded JPAL, which stands for the Abdul Latif Jameel Poverty Action Lab. JPAL is a global research organization headquartered at MIT that uses randomized evaluations (i.e., experiments) to answer policy questions related to poverty alleviation. The JPAL website, http://www.povertyactionlab.org, contains excellent resources about the methods of randomized evaluations, published studies, and policy briefs. Interested readers should also check out Innovations for Poverty Action, or IPA, a sister organization of sorts that is also a leader in the use of randomized evaluations to study important policy questions about global poverty. Yet, not everyone agrees. Educational psychologist Lee Cronbach certainly did not.11 Cronbach recognized the overlap in methods and designs, but he thought that program evaluation was really designed for program implementers and funders, and that the messy nature of programs required a loosening of research standards (Cronbach 1982). Just learn what you can. In their introductory text on evaluation, Rossi et al. (2003) strike a balance in views. Their answer is perhaps a bit unsatisfying, but I’d argue true nevertheless. It depends. Program evaluations should be as rigorous as logistics, ethics, politics, and resources permit. And no less. Is there a lower bound in terms of quality that should limit what is even worth doing? Probably, but the line is so context dependent that it is not sensible to attempt a definition. If there is one rule to follow, I’d suggest that it’s this: “don’t go beyond the data”. Everyone wants to claim “impact”, but not every evaluation can based on the design and implementation. Now we turn to the “M”, program monitoring. Program monitoring is concerned with the implementation of programs, policies, or interventions. How are resources being used? Is the program being delivered as intended (a.k.a. with fidelity)? How many people participate, and does the program reach the intended targets? These are all program monitoring questions. Accurate monitoring is essential for reporting to funders, but it’s also essential for all good evaluations. The reason is simple. If a program is shown to not “work”—to have no impact—the next question is why? Did the program fail to have an impact because the idea or theory behind the program was wrong (theory failure)? Or was it the case that the implementation of the program was so troubled that there was never a chance of having an impact (implementation failure)? Every trial should include ongoing monitoring or a formal process evaluation. 1.2.2 Research problems and questions Every study begins with a research problem. A research problem represents a gap in our knowledge. In academic research, this is another way of saying a gap in “the literature”. Usually when people speak of “the literature”, they mean scholarly or peer-reviewed journal articles. There is also something called “grey literature” that is more encompassing and harder to search systematically. Grey literature sources are typically disseminated through channels other than peer-reviewed journals. Examples could include technical reports or white papers published on the web. Research problems are typically broad. For instance, stakeholders might want to know how to increase the use of bed nets for children under 5 years of age. Or whether all children should receive deworming medication prophylactically. Stakeholders can refer to a wide range of people and organizations. Typically we mean donors (i.e., the public and private organizations that fund research and programs), policy makers (i.e., government officials and bureaucrats at international bodies like the WHO), program implementers (i.e., organizations like Doctors Without Borders that actually deliver services to beneficiaries, a.k.a. people), and scholars who study the topic or policy issue. These problems have something in common: they are solvable. In his introductory text on behavioral research methods, Leary (2012) writes that this is another key criterion for scientific research. The problems must be solvable. This does not mean easy; it just means that we can use systematic, public methods to gather and analyze data on the problem. Think of it this way: we can come up with a method for studying how to get more parents to ensure that their kids sleep under a mosquito net every night, but we don’t yet have a scientific method for determining whether there is a mosquito afterlife where these pests get to buzz around for all of eternity. In order to study a broad research problem, we must narrow to a more specific research question. de Vaus (2001) says there are essentially two types of research questions: Descriptive—what is going on? Explanatory—why is it going on? Let’s stick with the bed net example. If we want to study uptake or use of bed nets, we might ask a descriptive research question like, “How many children sleep under bed nets?” But this is too general. Children of what age? Living where? We also need to operationalize what we mean by sleeping under a bed net. It’s common in this line of research to ask about the previous night, as in the night before the survey. As we will discuss in the chapter on measurement, we have to consider challenges to getting valid information, such as recall difficulties. A better way to phrase the question might be, “What percentage of children under 5 years of age in Kenya slept under an insecticide treated net the previous night?” 1.2.3 Research designs As Glennerster and Takavarasha (2013) explain in their excellent practical guide to running randomized evaluations, different research questions require different research designs. We’ll spend most of our time in this book looking at strategies for answering the “why” questions. I lump them into three categories and differentiate them from descriptive designs: descriptive correlational quasi-experimental experimental Descriptive research The goal of descriptive research is to characterize the population. Often this means estimating the prevalence of a phenomenon or disease. 20% are illiterate. 36% have an unmet need for contraception. 9% are HIV positive. Description can also be qualitative in nature (e.g., thick description). Just about every study will have some descriptive element. Some studies are exclusively descriptive. A good example are the Demographic and Health Surveys, more commonly referred to as DHS surveys (yes, “surveys” is redundant). Every student of global health should come to know what the DHS Program has to offer. The program is funded by the U.S. Agency for International Development (USAID), and registered users can request access to data from more than 300 surveys conducted in 90+ countries. DHS surveys are a good example of demographic research. Demographers contribute to and use data sources like DHS surveys and national population and housing censuses to understand more about population size, structure, and change (e.g., birth, death, migration, marriage, employment, education). Many countries strive to conduct a census, or an enumeration of all citizens, every 10 years. The United Nations Statistics Division and the United Nations Population Fund (UNFPA) provide technical support (a.k.a., help) to countries preparing for, conducting, and analyzing a national population and housing census. These two organizations, in partnership with the United Nations Children’s Fund (UNICEF), maintain CensusInfo, a database of global census data. Here is the relevant table from the 2014 Kenya DHS Key Indicators Report for describing the prevalence of ITN use.12 This is a typical DHS cross tabulation (or crosstab) of the results. In this example, the percentage of children under the age of 5 that slept under an insecticide treated net the previous night in Kenya was 54.1%. This descriptive data is further disaggregated by residence and wealth quintile as is typical for DHS tables.13 Figure 1.6: Source: Kenya 2014 DHS Key Indicators Report, http://bit.ly/1g4NYS5 The data summarized in this table describes the problem of bed net use. Descriptive questions are well-suited for needs assessments. Before we can design a program or policy to increase bed net usage, for instance, we must to understand the need. In Kenya, almost half of children under 5 are not sleeping under insecticide treated nets according to the DHS. This is a particular concern for children living in areas of high risk. This DHS report is an example of a cross-sectional study. These are typically one-off surveys but can include other forms of data collection. The key is that it’s a snapshot. The goal is often description but might also include correlation. Cross-sectional studies are differentiated from panel or longitudinal studies by their participants; the latter include the same research participants (sample) over time in multiple studies, whereas cross-sectional studies only include a particular sample once. So even though the DHS Program will conduct a new survey in a country every five years or so, they always recruit a new sample of participants (a.k.a. “successive independent samples”). This makes the DHS surveys cross-sectional rather than panel or longitudinal in design. Correlational research This descriptive information sheds light on programmatic and policy priorities, but we have to go beyond describing the problem to make a difference. A helpful next step is often to build on descriptive insights by attempting to predict or explain the behavior or phenomenon. For instance, Noor et al. (2006) asked a correlational research question (edited below) about the factors associated with net use among children under the age of 5: Are wealth, mother’s education, and physical access to markets associated with the use of nets purchased from the retail sector among rural children under five years of age in four districts in Kenya? Correlational research asks questions about the relationship (a.k.a. association) between two or more variables. In this case, ITN use and a variety of potentially influential factors, such as household wealth and a mother’s education level. You’ll encounter different labels for variables, and it can be confusing to keep straight at first. The behavior Noor et al. are trying to predict, bed net use, is the dependent variable, often referred to as the outcome, response variable, or simply Y. The factors thought to be related to ITN use are the independent variables. Some disciplines will call them predictor or explanatory variables. Sometimes they are controls, exposures, or simply X. This will become more clear as we go. Noor and colleagues reported that only 15% of children in the rural study sample slept under a net the previous night—a much lower percentage than the national prevalence reported by recent DHS surveys. As shown in the table below, they also found that several factors were associated with higher odds of bed net use, including: greater household wealth, living closer to a market center, not having older children present in the household, having a mother who is married and not pregnant, being younger than 1 year old, and having an immunization card. Figure 1.7: Source: Noor et al. (2006), http://bit.ly/1HoltVo We’ll review in detail how to read tables like this in later chapters, but it might be helpful to preview some concepts here. The results in this table come from a multivariable logistic regression. The authors describe the model they fit in the article, but we won’t worry ourselves with these details. Instead, let’s highlight a few key points. The table starts with household-level predictors of net use, specifically household wealth quintile. The first two columns show us the number and percentages of households that have or do not have retail sector nets, disaggregated by wealth quintile. So of all the households without retail sector nets, 690 or 21.6% were classified as being the most poor. The distribution looks a bit different for households with nets; 40.1% of households with retail sector nets were classified as being the least poor. This makes intuitive sense: if you are poor, you are less likely to purchase a net from the market. The next three columns give us the results of the regression. Since wealth quintiles have different categories, the authors set one category—the most poor—to be the reference category. So the results will be relative to the poorest households. As you can see, the odds of using a net are 10.17 higher among the “least poor” compared to the “most poor”. This does not tell us why wealthier households are more likely to use nets for their young kids, but we know that there is some relationship here. Remember, however, that 10.17 is just what we call a point estimate for the odds ratio. The 95% confidence interval ranges from 5.45 to 18.98. We’ll talk more about the specifics as we go, but it’s important to get in the habit of evaluating the uncertainty of every estimate. In this case, it’s pretty clear that having more money is associated with better preventive behaviors. You will often see descriptive and correlational studies like the DHS and Noor et al. classified as non-experimental or observational studies. Other observational designs include cohort and case-control studies (the topic of a later chapter). Researchers use these designs to determine whether there is an association between some exposure and a disease. Observational studies are the bread and butter of epidemiology. Epidemiologists often conduct cross-sectional studies to estimate the prevalence and incidence of different disorders as well as correlational research to understand risk and protective factors. Prospective cohort In a prospective cohort study, healthy participants are recruited and followed into the future for a period of time. For instance, Lindblade and colleagues (2015) conducted a prospective cohort study in Malawi to test the efficacy of ITNs in an area of moderate resistance to pyrethroids, a common class of insecticide. A prospective cohort of 1,199 healthy children aged 6-59 months was followed for a year. This group of children make up the cohort, and the fact that they were recruited and followed for a period of time into the future makes the design prospective. Compared to no bed nets, ITNs reduced the incidence of malaria infection by 30%. This is promising, but the study design has limitations. One important limitation is that the children were not randomized to ITN access. So it could be the case that children who used the ITNs were somehow different from the children who did not use the ITNs. This is a potential selection bias, a threat to internal validity. You’ll learn more about such threats in a later chapter. The basic challenge for causal inference is that the design does not rule out the possibility that something other than ITN use accounted for the reductions in malaria infections. Case-control Sometimes it is not possible to recruit a group of healthy people and wait to see who gets sick. Imagine having to wait a decade or more to see who develops rare diseases like gliomas. This would be a very expensive study that would need to involve thousands of people to study such a rare disease that takes time to emerge. A case-control study might be a better fit. In this design, researchers identify people with the disease (cases) and without the disease (controls) and ask them about past exposures. Obala et al. (2015) did this in Kenya with 442 children hospitalized with malaria and healthy matched controls without evidence of malaria. They wanted to know why there is a high malaria burden despite high ITN coverage. The research team visited visited the home of each case and control and asked questions about ITN coverage and recent use, along with measuring the parasite burden of family members, mapping nearby potential vector breeding sites, and assessing neighborhood ITN coverage. Obala and colleagues found that ITN coverage was not correlated with hospitalizations, but consistent ITN use decreased the odds of hospitalizations by more than 70%. As with prospective cohort designs, there is a risk of selection bias. In this case, we have to be concerned that the matching process was not perfect. The matching was done on the basis of age, gender, and village. But there could be unmeasured ways in which the cases and controls differ, which would undermine the results. Correlational studies can yield important insights of course, but they have limitations. You’ve probably heard that correlation does not equal causation. For instance, did you know there is a nearly perfect correlation between the per capita consumption of cheese and the number of people who have died by becoming tangled in their bedsheets? (If you just put down the hunk of aged cheddar you were eating, please keep reading this book!) That said, all studies have limitations and tradeoffs. Designing a good study is a process of weighing scientific objectives with logistical constraints, ethical considerations, time, money, and a host of other factors. Keep reading to learn more about how to make these tough calls. Experimental and quasi-experimental research Without a doubt, the correlational results described in studies like Noor et al. (2006) can help to design programs and policies. But what we often want to know is whether our programs and policies “work”. When we ask whether something works, it’s a question of impact, and impact evaluations use experimental or quasi-experimental research designs. (Experimental and quasi-experimental are addressed in more detail in later chapters) The goal of impact evaluations is causal inference. Does X cause Y? Does a particular program or intervention or treatment increase or decrease a particular outcome? For reasons we will explore in greater detail later, experimental research designs offer the cleanest estimate of impact. The hallmark of an experimental design is that we as researchers manipulate some independent variable and examine changes to some dependent variable that result. A common example in global health is the randomized controlled trial (RCT) in which some units, such as individuals, schools, or communities, are randomly assigned to receive an intervention (treatment) or not (control). We measure an outcome after the intervention period and estimate the average difference between the two study arms, also known as the average treatment effect. Experiments are the “gold standard” in the eyes of many people, but researchers are not always able to assign people or clusters to study arms or otherwise manipulate an independent variable. Logistics and ethics can get in the way. In these cases, researchers might rely on non-experimental designs commonly referred to as “quasi-experimental” designs. The name of the game in quasi-experimental research is to reduce threats to internal validity, something that randomization pretty much takes care of naturally. Beware: not all non-experimental designs are created equal. We’ll discuss several of them later in this book, including: pre-post post-test only difference-in-differences multivariate regression and matching regression discontinuity instrumental variables interrupted time series An important global health policy question that has been studied using experimental and quasi-experimental methods is the impact of user fees on the adoption of health goods, such as bed nets. Advocates of fees argue that free distribution is not sustainable and leads to waste when people who don’t need or want the goods are recipients. There is also an argument that people only value what they pay for, so removing fees will make people less likely to use goods like bed nets. The flip side is that the provision of some health goods, in economics-speak, creates “positive externalities” and should therefore be financed with public dollars. What this means is that some interventions have spillover effects whereby people who are not treated still experience some indirect effect. A good example of a spillover effect is vaccines and the resulting herd immunity. Hawley et al. (2003) showed a similar protective effect of ITN use on child mortality and other malaria-related outcomes among households without ITNs that were located within 300 meters of households with ITNs. So we know that there is evidence that ITNs have direct (Phillips-Howard et al. 2003) and indirect benefits. The research question is then how to increase coverage and use of nets. Is free distribution the best strategy, or should users have to spend something to get a bed net that might retail for a price that is out of reach for many poor households? Quasi-experimental Agha et al. (2007) used a quasi-experimental design to estimate the impact of a social marketing intervention on ownership and use of ITNs in rural Zambia. Nets that commonly sold for USD $27 were subsidized and sold for $2.50 at public health clinics. Neighborhood health committees were established and 600 volunteer “promoters” were trained to teach residents about malaria and encourage them to purchase the nets. To estimate the impact of the intervention, the authors analyzed data from post-intervention surveys in three intervention and two comparison districts. This study design was quasi-experimental because the districts were not randomized to the intervention or control arms. Figure 1.8: Source: Agha et al. (2007), http://bit.ly/1MkO5a0 Agha and colleagues reported that ITN ownership and use was higher in intervention districts according to the post-intervention data, but were careful to avoid going ‘beyond the data’ to claim evidence of a causal relationship. There are several design limitations to consider here, and you will learn more about how to spot these issues as we go. Briefly, we can note that (i) the authors did not randomize districts to study arms and (ii) no baseline (a.k.a. pre-treatment) data was collected. Experimental studies benefit from but do not require baseline (or pre-intervention) data because randomization usually ensures that the treatment and comparison groups are similar at the start—if enough units are randomized. But a non-randomized study like this leaves itself open to criticism without baseline data to show that the intervention and comparison districts were similar before the intervention was introduced. The results suggest that they were different after the intervention period, but we can’t be sure this was caused by the intervention itself. Given the limitations, how should we view the results? If this was one of the first studies on the topic, we would view it as a starting point that would encourage more rigorous investigations. As part of a larger body of evidence, however, it would probably be passed over in systematic reviews and meta-analyses—studies of studies—because of the limitations of the design for causal inference. Experimental Another limitation of Agha et al. (2007), at least for our purposes, is that it does not provide a direct answer to our policy question: should ITNs be free or subsidized? Fortunately, other studies fill this gap. Cohen and Dupas (2010) used an experimental design to study this question in Kenya where malaria is the leading cause14 of morbidity and mortality. The authors randomly assigned 20 prenatal clinics in an endemic region to 1 of 5 groups: a control group that did not distribute ITNs, a free distribution group, a group that charged 10 Ksh per ITN (97.5% subsidy), a group that charged 20 Ksh (95% subsidy), and a group that charged 40 Ksh or about $0.60 USD (90% subsidy). When units like clinics, schools, and villages are randomized, we refer to the design as a cluster-randomized trial, or CRT. The authors followed up a subset of pregnant women over time and found that those who paid a subsidized price were no more likely to use the bed nets than women who received one for free. They also found that the increase in price from $0 to $0.60 USD reduced demand for ITNs by 60%. This implies that the cost-sharing model of having women pay something for ITNs will reduce coverage. This is bad for the women who forgo a net purchase because of the direct prevention effects of ITNs, but we know from Hawley et al.’s work that it’s also bad for the community since ITNs have spillover effects. Cohen and Dupas conclude that free distribution would ultimately save more child lives. 1.2.4 Research methods If research designs are strategies for answering research questions with the best possible evidence, then research methods are the tactics for obtaining the evidence. Often methods are divided into three broad categories: quantitative qualitative mixed Quantitative methods are used to collect and analyze numerical data. This includes binary or dichotomous** data (e.g., hospitalized or not), categorical data (e.g., wealth quintile), and continuous data (e.g., hematocrit). A good example of a quantitative method is a survey in which people are asked to answer questions with fixed response options or provide numerical values, such as their monthly income. Lab tests resulting in disease classifications (yes/no) or a measurement such as the number of blood cells in a sample of blood are also examples of quantitative methods. Qualitative methods focus on non-numerical data. Participant observation, interviews, and focus group discussion are common qualitative methods in global health. Qualitative methods are well-suited for obtaining thick description and for exploration. For instance, Scandurra et al. (2014) analyzed data from interviews, observations, photos, and videos to study perceptions and practices related to bed net care and repair in Uganda. As is typical of manuscripts based on qualitative data, the authors include illustrative quotes, such as this one regarding net repair from a 55 year-old female: [It] depends on one’s situation. If you have money, there is no need of sewing a net, you just buy a new one but if you are poor, you have to do it. So this is when you are poor. Scandurra et al. found that there are strong social norms around net hygiene and appearance. Dirt floors and indoor cooking with dirty fuel sources and little ventilation tarnish the look of nets, and as a result, nets get washed frequently and may reach their lifetime wash limit much sooner than commonly assumed. If true, this could have implications for preventive efficacy. Often qualitative methods are seen as being less rigorous because they are more flexible and do not lead to the same type of hypothesis testing and results compared to quantitative methods. But this is not true. As we’ll discuss in a later chapter, rigor is a characteristic of how the methods are applied rather than the methods themselves. Your choice of methods should be based on your research question. It’s often the case that impact evaluations use quantitative methods, but there is not a 1-to-1 match between research designs and methods. Many studies incorporate both quantitative and qualitative methods, and we refer to this as mixed methods. Sometimes the goal of mixing methods is triangulation of results with respect to the same research question. Other times we begin with qualitative work to develop the tools and measures that we will use in a trial. When qualitative work follows a quantitative phase, the goal is often to explain or explore results in more depth that was not possible with the quantitative data. Increasingly you will see RCTs complement their use of quantitative methods with qualitative inquiry (O’Cathain et al. 2013). Alaii et al. (2003) provide a good example. The authors of this paper incorporated qualitative interviews on non-adherence into a larger randomized trial of the efficacy of ITNs on child morbidity and mortality in Kenya (Phillips-Howard et al. 2003). They wanted to better understand why people, particularly children under the age of 5, were not using their ITNs correctly. Alaii et al. found that more than a quarter of individuals were non-adherent, often due to excessive heat. 1.2.5 Theories and hypotheses Many impact evaluations fit the label of black box evaluations, meaning that they don’t focus on why programs do or don’t have an impact. The evaluation is not guided by theory, and the hypotheses are as simple as “the program will have an impact on the outcome”. White (2009) outlines a strategy for changing this and moving to theory-based impact evaluations (White 2009). Leary (2012) defines a theory as “a set of propositions that attempts to explain the relationships among a set of concepts”. In quantitative research, you could replace “propositions” with “hypotheses” and “concepts” with “variables”. As we reviewed earlier, the logical approach in quantitative research is often deductive. You start with theory and develop research hypotheses that are then tested. A hypothesis is an a priori prediction about what will occur—about how constructs are related. If the hypothesis is supported by the data, you have support for the underlying theory. If your study is well designed, it might be given more weight as other researchers consider the evidence in support of the theory. In theory testing, 1+1 does not always equal 2. For a hypothesis to be scientific it should be falsifiable, or testable. To return to a silly example from earlier, the following would not be a research hypothesis because it cannot be tested: “if a mosquito is killed, it goes to mosquito heaven”. Maybe, but we can’t test this hypothesis. Science progresses through the possibility of falsification, so hypotheses must be engineered to potentially fail. Proving and disproving theories To return to an earlier example, some people advocate against the free distribution of ITNs out of the belief that there is a “sunk cost” effect when having to spend money for a bed net; people will use the net more to justify their purchase (Arkes and Blumer 1985). In this case, the theory is one of sunk costs directing behavior. The falsifiable hypothesis tested by Cohen and Dupas (2010) was that people who paid a non-zero price for an ITN would use the ITN more than those who received the ITN for free. As you will recall from our discussion, there was not support for this hypothesis. So the theory is rejected, right? Not necessarily. Leary (2012) offers some helpful advice for thinking about proof and disproof. Proof is logically impossible, whereas disproof is practically impossible. Frustrating, right? Proof is not possible It helps to state the theory and hypothesis as an if-then statement. For example, “If the theory of sunk cost effects is true, then people who pay for an ITN will be more likely to use it than people who get an ITN for free.” If the theory is true, the hypothesis will be true. What happens if you flip this statement? If you find evidence that the hypothesis is true—as you might in a study—does it mean that the theory is true? Cohen and Dupas (???) did not find support for the hypothesis that people who paid a non-zero price for an ITN would use the ITN more than those who received the ITN for free. But let’s pretend for a moment that they did. Would that prove the sunk cost theory? No, logically it can’t. It would be like concluding that my raging fever is malaria because I have mosquito bites all over my arm. The “theory” here would be that my fever is malaria, and the hypothesis would be that I must have been bitten by a mosquito. If I have mosquito bites all over, my fever must be malaria, right? Well, no. I was bitten by a mosquito, but maybe the scene of the crime was my backyard in the eastern United States where we don’t worry about malaria. So in this case, the hypothesis was true, but it doesn’t prove the theory. Disproof is possible, but uncommon What if the hypothesis was not supported, and I was not bitten by mosquitos? Could my “theory” be true—could my fever be malaria? No. And logic would support this. If the hypothesis is derived from the theory, and if the hypothesis is not supported, the logical inference is that the theory is wrong. Yet, we still shy away from concluding that the theory is wrong. The reason is simple: complexity. A study like Cohen and Dupas (???) could fail to reject the null hypothesis that use does not differ between free and subsidized clients—thus not supporting the hypothesis of different use rates—but there are many practical reasons for this. For instance, maybe their measure of bed net use was systematically flawed and hid the difference as a result. The possibilities are endless. This is partly why journals are hesitant to publish null results. Science marches on So, where do we go from here? Answer: the literature! No one study is enough to lead people to discard a theory. But several null results might be. Conversely, no study ever proves a theory, but an accumulation of studies showing support for the theory-derived hypothesis builds confidence in the theory. Particularly when the studies are conducted by different researchers, across different populations, and triangulating with multiple methods. Of course you see the challenge here. How do researchers know that several studies have failed to support a certain theory if journals are reluctant to publish null results? And if negative evidence is missing, won’t the positive evidence be over-represented in the literature? Yes. This is the problem of publication bias, or the file drawer problem, and there is not an easy answer. Efforts like AllTrials to register and report the results of all trials, regardless of outcome, seem like a step in the right direction. So, to the literature we go. Test Yourself References "],
["literature.html", "2 Searching the Literature 2.1 Start with Systematic Reviews and Meta-Analyses 2.2 Devising a Search Strategy 2.3 For the Love of Everything Holy Use a Reference Manager", " 2 Searching the Literature The starting point of every research study is a literature review. To know where you are going, you need to know where the field has been. Technology makes this easier in some ways than it has been in the past, but we’re swimming in information, and the pool gets deeper every day. A lot deeper, actually. Google’s former CEO Eric Schmidt has said we create as much information every two days as we did from the beginning of time through 2003. Two days! And he said this back in 2012, so it’s an even shorter time span today. Of course the “cat photo” to “research finding” ratio is probably something like 1,000,000:1 nowadays, but this only makes the point that good information can be hard to find. In this chapter we’ll discuss a strategy for quickly getting a sense for the state-of-the-art in health research, and then outline the steps you need to take to ask a good research question and search the literature for primary sources. 2.1 Start with Systematic Reviews and Meta-Analyses Repeat after me: I will not start my research by Googling “malaria”. I will not start my research by Googling “malaria”. I will not start my research by Googling “malaria”. If your topic is malaria and you’re not sure if the vector is mosquitos or monkeys, then Wikipedia is probably a good first stop. There’s no shame in that. Otherwise, it is always a good idea to start with a check for relevant systematic reviews or meta-analyses. Finding a good review beats Googling “malaria” any day. 2.1.1 Meta-Analyses A meta-analysis is a quantitative approach in which the results from multiple studies are combined to estimate an overall effect size. We’ll talk more about effect sizes later, but the concept is pretty simple. Let’s use a meta-analysis by Radeva-Petrova et al. (2014) as an example. The authors reviewed 17 studies of the effects of chemoprevention on pregnant women living in malaria-endemic areas. The basic question they set out to answer with their review was as follows: Do women who take antimalarial medication during pregnancy have a lower risk of getting infected with malaria, and thus a lower risk of experiencing the bad health outcomes that are associated with malaria? One indicator of malaria infection is parasitaemia, or the presence of malaria parasites in the blood. If chemoprevention has some preventive effect, you’d expect to see less parasitaemia among women exposed to the medication (aka, treatment). Few interventions are 100% effective, so we often talk about reductions in the risk of bad outcomes like malaria. This is one type of effect size, a measure of the strength or magnitude of a relationship, such as a the relationship between taking a medicine and experiencing a bad outcome. Here is a forest plot from Radeva-Petrova et al. (2014) that shows the results of 10 studies (8 trials) that compared cases of parasitaemia among 3,663 pregnant women who were randomized to an intervention group (n=2,053) that received some preventive antimalarial drug or to a control group (n=1,610) that received a placebo (or nothing). Figure 2.1: Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj Here’s how Lewis and Clarke (2001) describe a forest plot: In a typical forest plot, the results of component studies are shown as squares centred on the point estimate of the result of each study. A horizontal line runs through the square to show its confidence interval—usually, but not always, a 95% confidence interval. The overall estimate from the meta-analysis and its confidence interval are put at the bottom, represented as a diamond. The centre of the diamond represents the pooled point estimate, and its horizontal tips represent the confidence interval. Significance is achieved at the set level if the diamond is clear of the line of no effect. The plot allows readers to see the information from the individual studies that went into the meta-analysis at a glance. It provides a simple visual representation of the amount of variation between the results of the studies, as well as an estimate of the overall result of all the studies together. Forest plots increasingly feature in medical journals, and the growth of the Cochrane Collaboration has seen the publication of thousands in recent years. Lewis and Clarke (2001) discovered that the first forest plot was published in 1978, and first used in a meta-analysis in 1982. The name lagged behind, appearing first in 1996, apparently referring to the forest of lines typical of most forest plots. Details about each study are reported as rows in this figure. Take a look at the study by Shulman et al. (1999) in row 6. This study found that 30 of the 567 women in the intervention group tested positive for parasitaemia (i.e., malaria). This compared to 199 of the 564 woman in the control group. This is a risk ratio of 0.15—(30/567)/(199/564) = 0.15—which means that chemoprevention reduced the risk of parasitaemia by 85%. This is a huge effect size! The effect size for each study is presented in the far right column and depicted graphically in the size of point estimate square. All of the point estimates fall to the left of the line of no effect (&lt;1), thus favoring chemoprevention because you want to reduce the risk of this bad outcome. [A risk ratio of 1 would indicate no difference in risk, and a ratio &gt;1 would mean the risk is higher among the intervention group, thus favoring the control group.] The overall (pooled) effect size is shown last as 0.39, or a 61% reduction in the risk of parasitaemia. We won’t bother ourselves with the calculation of this pooled effect size, other than to note that it’s not as simple as averaging the 10 studies. This is because the studies were not given equal weight, as you can see in the “weight” column. For instance, Greenwood et al. (1989) only had a sample size of 21+13=34 children. As a result, the effect size estimate is very noisy. The 95% confidence interval is wide and crosses 1. Consequently, it’s weight is lower than others at 6.7%. Simply put, studies weaker research designs get less weight in the analysis. So here in one figure we get a summary of the best available evidence and an estimate of the overall effect size, with uncertainly intervals. You can’t get that from a Google search. 2.1.2 Systematic Reviews You might be wondering how Radeva-Petrova et al. (2014) found these studies in the first place. The answer is through a systematic review of the literature. Most, if not all, meta-analyses will be completed as part of a systematic review of the literature, and every systematic review is a type of literature review. But not every literature review is a systematic review, even if done systematically. Figure 2.2: Literature reviews, systematic reviews, and meta-analyses As you can see from the table below, a systematic review requires a number of steps that are good practice, but too thorough and time-consuming for the general literature review you might prepare when starting your work. Nevertheless, you need to know the general process of preparing a systematic review to evaluate the quality of the reviews you read, and you’ll hopefully pick up some good habits along the way. Table 2.1: Comparing systematic reviews and literature reviews. Systematic Reviews Literature Reviews The goal of a systematic review is to to be comprehensive and include every relevant article. The literature review that you write for the introduction of your manuscript is not expected to be exhaustive. For this reason, most systematic reviews are conducted by teams given the large scope of the work. literature reviews can be handled solo. Systematic reviews must define and follow a method that can be replicated, just like any other study. Literature reviews, on the other hand, don’t have to follow such rigid methods or make the methods explicit. Most systematic reviews pre-register this plan, meaning that the authors submit their planned methods to a registry like PROSPERO prior to conducting the study. Pre-registration gives other researchers confidence that the team is not cherry picking results at the end to make an interesting paper. It also lets other researchers know that a group is already working on the same review, thus signaling that their work might duplicate efforts and fail to get published. Not the case of for literature reviews. Included in these pre-registration plans will be a specific search strategy with exact search terms for individual scholarly databases so other researchers can recreate the search. It’s a good idea to do the same for a literature review, even if not a strict requirement. Similarly, a systematic review must also outline clear criteria for including and excluding studies (e.g., keep if assignment to study arms was random). With these criteria in place, team members screen all search results, usually starting with title and abstract reviews only and moving to full text reviews as the pool of eligible studies dwindles. Screening for a literature review is typically less intensive. Systematic reviews also develop and follow guidelines for extracting details from every included study, such as numbers of participants and key outcomes. An annotated bibliography might suffice for a literature review. Finally, teams conducting systematic reviews formally assess the quality of each included study, including the potential for bias, and take these assessments into account when synthesizing the results. This process is more ad hoc for literature reviews. Where to find systematic reviews Three excellent sources for finding systematic reviews (and meta-analyses) in global health are the Cochrane Library, the Campbell Collaboration, and 3ie. You can also get to many of the reviews in these databases by searching within PubMed using the Clinical Queries feature. How to read systematic reviews Abstract and plain language summary Cochrane reviews follow a standard format that can look overwhelming at first, but is actually quite easy to read and understand. As with most journal articles, Cochrane reviews begin with an Abstract. Next comes a Plain language summary which can be helpful for newcomers to a particular topic. Radeva-Petrova et al. (2014) include the following passage in their plain language summary: For women in their first or second pregnancy, malaria chemoprevention prevents moderate to severe anaemia (high quality evidence); and prevents malaria parasites being detected in the blood (high quality evidence). It may also prevent malaria illness. We don’t know if it prevents maternal deaths, as this would require very large studies to detect an effect. This one paragraph brings us up to speed with the state of the science for preventing malaria and its effects among pregnant women living in malaria-endemic areas (and points you to some gaps in the literature!). Google does not filter the evidence in this manner. Starting with systematic reviews pays off almost every time. Summary tables Next come the Summary tables, such as the one presented below from Radeva-Petrova et al. (2014). These tables round out everything you need to make your initial judgment. Figure 2.3: Malaria chemoprevention for pregnant women living in endemic areas. Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj The first comparative risk column shows the assumed risk among the control group. For instance, the risk of antenatal parasitaemia is 286 events per every 1,000 people. This is the median control group risk across eight trials of 3,663 women. The relative risk is 0.39—recall that this is the pooled, or “meta” effect size—so you can see how the corresponding risk among the intervention group is 286*0.39=111 per 1,000 people.15 As shown in the final column, the quality of this evidence is rated as “high”. The authors are referring here to GRADE criteria, a systematic approach to evaluating the quality of empirical evidence: High—Further research is very unlikely to change our confidence in the estimate of effect. Moderate—Further research is likely to have an important impact on our confidence in the estimate of effect and may change the estimate. Low—Further research is very likely to have an important impact on our confidence in the estimate of effect and is likely to change the estimate. Very Low—We are very uncertain about the estimate. Background Much of what you want to know you can learn from the abstract, summary text and tables, and forest plots (if included). If you keep reading, you’ll come next to the Background section. This is typically a short overview that explains what gaps in our knowledge the review is intended to fill. Radeva-Petrova et al. (2014) use this section to present a conceptual framework for malaria prevention during pregnancy. Figure 2.4: Drugs for preventing malaria in pregnancy: conceptual framework. Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj Methods The Methods section details how the review was organized and conducted. The purpose of this section is to provide enough detail to enable other researchers to attempt to replicate the review. The main components are:16 A description of the population and intervention. The key outcomes of interest. The search strategy and databases. Inclusion and exclusion criteria for studies. Procedures for extracting information from each study. Procedures for assessing bias and conducting a meta-analysis (if one is included) Results The Results section typically begins with details about how many primary articles were identified, screened, and excluded, typically presented graphically with a flow diagram like the one below from Radeva-Petrova et al. (2014). Figure 2.5: Study flow diagram. Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj Once the included studies are identified, it’s customary for review authors to report on the quality of the evidence presented in each study. We’ll discuss the nature of these sources of bias in a later chapter, but you should familiarize yourself with these heatmaps. While a bit on the ugly side, they provide a useful summary of bias. As a future producer of research, you should start to look at these figures and think, “how can I make sure my studies are full of green pluses?” Figure 2.6: Risk of bias summary: review authors’ judgements about each risk of bias item for each included trial. Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj Discussion and conclusions Discussion sections provide a short summary of the findings, commentary on the quality of the evidence, and thoughts about what the review adds to the existing literature on the topic. A discussion tends to be short relative to the size of the overall review. Discussion sections are often followed by a brief statement of the authors’ conclusions. This is an opportunity for the authors to frame the results in terms of the implications for practice and research. Radeva-Petrova et al. (2014) conclude: Routine chemoprevention to prevent malaria and its consequences has been extensively tested in RCTs, with clinically important benefits on anaemia and parasitaemia in the mother, and on birth-weight in infants. In other words, “chemoprevention works” in this context. Appendices Reading the appendices will give you a sense of what it takes to put together a systematic review. There are usually tables after tables of characteristics of included and excluded studies, often followed by dozens of forest plots if the systematic review includes a meta-analysis with several outcomes or populations of interest. Radeva-Petrova et al. (2014) wrap up on page 120! 2.2 Devising a Search Strategy Hopefully at this point you’ll agree that it’s a good idea to start with a systematic review, not a search engine. Of course not every topic has been the subject of a recent systematic review or meta-analysis, so you’ll sometimes need to search the primary literature yourself. I’ll show you how, but first you need to clearly define what you’re looking for. 2.2.1 Asking a research question Here’s a helpful mnemonic for creating a good clinical question: PICO. P Patient, Population, or Problem I Intervention, Prognostic Factor, or Exposure C Comparison O Outcome Let’s try to use PICO to create a research question for a portion of the Radeva-Petrova et al. (2014) systematic review. The problem we want to address is malaria infections. The population is pregnant women living in malaria-endemic areas. Not every clinical question involves testing of a treatment or intervention, but we’ll focus a lot on these types of questions in this book. For the example at hand, the intervention would be malaria chemoprevention. [Prognostic factor refers to covariates that could influence the prognosis of the patient. An exposure would be something that we think might increase the risk of an outcome.] Similarly, not every question involves a comparison group. Randomized trials always will. In this example, the comparison is nothing or a placebo. Radeva-Petrova et al. (2014) examine a number of outcomes. We’ll focus on parasitaemia. We can combine all of this into a research question: Among pregnant women living in malaria-endemic areas, is chemoprevention more effective than a placebo at preventing parasitaemia? 2.2.2 Approaches With your basic research question outlined, you’re ready to begin searching. At the beginning you might take a quick and dirty™ approach to get started. Eventually you’ll need to graduate to a proper search strategy to be more systematic, even if your end goal is not a capital “S” Systematic review. Quick and dirty A reasonable initial approach is to find a few recent articles to get a quick sense of what is out there. Google Scholar could come in handy here. For instance, my advanced Google Scholar search for “malaria chemoprevention pregnant parasitaemia” (limited to recent years) identified a paper by Braun et al. (2015) on the use of intermittent preventive treatment in pregnancy (IPTp) with sulfadoxine–pyrimethamine (SP)—a specific type of chemoprevention—on malaria infections among pregnant women in western Uganda. Customize your Google Scholar experience by clicking on the gear icon. Enable use of a bibliography manager, and click on “Library links” to add your library to get links to full text. A good starting point for future searching is to note an article’s keywords. Not all journals print keywords, but if they do, you’ll probably find them right after the abstract. Next comes the introduction. Some journals and disciplines have very brief introduction sections and might not be of much help. This is often true in medicine and public health. The discussion section is also a place to look for new leads. Authors typically use the discussion to link the study results to the existing literature, demonstrating how the results add to what is already known. After looking at the introduction and discussion sections, it’s often useful to skim the references to get a sense of which journals publish this type of work. If a certain journal appears to be a common outlet for this work, a scan of the journal’s table of contents for recent issues could be useful.17 If you have access to a university library, you can learn more about the scholarly journals in a field by looking up Journal Citation Reports. This annual report ranks the journals in each field according to impact factors. Impact factors are one metric used to evaluate the importance of a journal in its field. More systematic Plan and document your search strategy Whether or not you are conducting a capital “S” Systematic review, it’s a good idea to plan and document your search. You don’t need to be as thorough in a lit review as you would for a systematic review, but it wouldn’t hurt to take a page from the approach. Let’s look at Radeva-Petrova et al. (2014) for some inspiration. Every good systematic review will include a table or appendix like this one to make the method reproducible. If you and I run this search query at the same time on two different computers, we should get the same results. Figure 2.7: Source: Radeva-Petrova et al. (2014), http://bit.ly/1U3q2Oj For the purposes of your literature review, you don’t necessarily need to ensure that other people can recreate your results, but you should make sure that you can. If you can create an account with the database, do it and login to save your searches. Also, differences in the design of each database and interface often require you to customize your search. If you are conducting an actual systematic review that you wish to publish—as opposed to just searching the literature systematically—then you would benefit from consulting with a clinical librarian who will be familiar with the intricacies of building search strategies. Selecting a database As you can see from the table, Radeva-Petrova et al. (2014) searched five databases. MEDLINE is probably the most well known of this group. When you search in PubMed, PubMed is searching the MEDLINE database. This is typically a good place to start to find health-related studies. Talk with a research librarian to understand if other databases might be a better choice for your topic. Generate search terms Once you decide on a database, you need to generate search terms. Start with the keywords published with the sample articles you dig up. You can learn a lot about potential keywords by searching for MeSH terms. MeSH, which stands for “Medical Subject Headings”, is a controlled vocabulary thesaurus that is used to index articles in PubMed. This thesaurus is helpful because there are often many ways to refer to the same phenomenon. For instance, the MeSH term for “breast cancer” is “Breast Neoplasm”. When you search for “breast cancer” in PubMed, the database helps you out by casting a wider net: &quot;breast neoplasms&quot;[MeSH Terms] OR (&quot;breast&quot;[All Fields] AND &quot;neoplasms&quot;[All Fields]) OR &quot;breast neoplasms&quot;[All Fields] OR (&quot;breast&quot;[All Fields] AND &quot;cancer&quot;[All Fields]) OR &quot;breast cancer&quot;[All Fields] Turns out there are a lot of ways that we refer to breast cancer! The following entry terms are indexed by PubMed humans to the MeSH term “breast neoplasms”: Breast Neoplasm Neoplasm, Breast Neoplasms, Breast Tumors, Breast Breast Tumors Breast Tumor Tumor, Breast Mammary Neoplasms, Human Human Mammary Neoplasm Human Mammary Neoplasms Neoplasm, Human Mammary Neoplasms, Human Mammary Mammary Neoplasm, Human Mammary Carcinoma, Human Carcinoma, Human Mammary Carcinomas, Human Mammary Human Mammary Carcinomas Mammary Carcinomas, Human Human Mammary Carcinoma Breast Cancer Cancer, Breast Cancer of Breast Mammary Cancer Malignant Neoplasm of Breast Malignant Tumor of Breast Breast Carcinoma Cancer of the Breast Back in the world of mosquitos, the MeSH term for “malaria” is “malaria”, conveniently, and a search for this term in PubMed actually searches: &quot;malaria&quot;[MeSH Terms] OR malaria[Text Word] The following entry terms are indexed to the MeSH term “malaria”: Remittent Fever Fever, Remittent Paludism Plasmodium Infections Infections, Plasmodium Infection, Plasmodium Plasmodium Infection Marsh Fever Fever, Marsh Running your search Once you have some initial search terms, it’s time to build and run your query. This will be an iterative process, full of trial and error. You might start with 200,000 results. Some terms and combinations will fail to narrow this field. Others will trim too much. Figure 2.8: Boolean operators: AND, OR, NOT You’ll need to know some basic Boolean operators to be an effective searcher: AND, OR, NOT. For instance, let’s consider the search PubMed runs when you enter “malaria OR pregnancy”: (&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) OR (&quot;pregnancy&quot;[MeSH Terms] OR &quot;pregnancy&quot;[All Fields]) These four terms are combined with OR, meaning we keep results that match any of these terms. At the time of writing, PubMed returns 922,588 results. Of course it would make more sense to search for “malaria AND pregnancy”, instead of “malaria OR pregnancy”: (&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) AND (&quot;pregnancy&quot;[MeSH Terms] OR &quot;pregnancy&quot;[All Fields]) The first two terms and last two terms are combined separately with OR. These combinations are then combined with AND (notice the use of parentheses to segment the operations), dropping our pool of results to 4,203 records. The AND operator will always maintain or decrease the number of results. If we want to limit the results humans, we can add AND &quot;humans&quot;[MeSH Terms] to the end.18 Doing so drops our pool of results to 3,798. (&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) AND (&quot;pregnancy&quot;[MeSH Terms] OR &quot;pregnancy&quot;[All Fields]) AND &quot;humans&quot;[MeSH Terms] Alternatively, we could use the NOT operator to limit the results to non-humans. Not surprisingly, we get 405 records. (If you are making a surprised face, think about it this way: 405 + 3,798 = 4,203 or non-human results + human results = all results) ((&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) AND (&quot;pregnancy&quot;[MeSH Terms] OR &quot;pregnancy&quot;[All Fields])) NOT &quot;humans&quot;[MeSH Terms] Let’s return to our PICO question and use Boolean operators to combine the components. Among pregnant women living in malaria-endemic areas, is chemoprevention more effective than a placebo at preventing parasitaemia? Here’s what we want to do in plain English: humans AND pregnant women (redundant, but we’ll keep to show the strategy) AND malaria endemic AND chemoprevention AND randomized controlled trial AND parasitaemia Within each group, we have several ORs to consider. The parentheses can get confusing, so let’s build the search one line at a time. (&quot;humans&quot;[MeSH Terms] OR &quot;humans&quot;[All Fields]) AND (&quot;pregnant women&quot;[MeSH Terms] OR (&quot;pregnant&quot;[All Fields] AND &quot;women&quot;[All Fields]) OR &quot;pregnant women&quot;[All Fields]) (&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) AND endemic[All Fields] (&quot;chemoprevention&quot;[MeSH Terms] OR &quot;chemoprevention&quot;[All Fields]) OR (&quot;chloroquine&quot;[MeSH Terms] OR &quot;chloroquine&quot;[All Fields]) OR (&quot;pyrimethamine&quot;[MeSH Terms] OR &quot;pyrimethamine&quot;[All Fields]) OR (&quot;proguanil&quot;[MeSH Terms] OR &quot;proguanil&quot;[All Fields]) OR (Pyrimethamine-dapsone[All Fields]) OR (&quot;fanasil, pyrimethamine drug combination&quot;[Supplementary Concept] OR &quot;fanasil, pyrimethamine drug combination&quot;[All Fields] OR &quot;sulfadoxine pyrimethamine&quot;[All Fields]) OR (&quot;mefloquine&quot;[MeSH Terms] OR &quot;mefloquine&quot;[All Fields]) [Publication Type] OR &quot;randomized controlled trials as topic&quot;[MeSH Terms] OR &quot;randomized controlled trial&quot;[All Fields] OR &quot;randomised controlled trial&quot;[All Fields] parasitaemia[All Fields] OR &quot;parasites&quot;[MeSH Terms] OR &quot;parasites&quot;[All Fields] OR &quot;parasite&quot;[All Fields] All together now with ANDs. As I tap out these words on my keyboard, this search returns 513 records in PubMed. ((&quot;humans&quot;[MeSH Terms] OR &quot;humans&quot;[All Fields]) AND (&quot;pregnant women&quot;[MeSH Terms] OR (&quot;pregnant&quot;[All Fields] AND &quot;women&quot;[All Fields]) OR &quot;pregnant women&quot;[All Fields])) AND ((&quot;malaria&quot;[MeSH Terms] OR &quot;malaria&quot;[All Fields]) AND endemic[All Fields]) AND (&quot;chemoprevention&quot;[MeSH Terms] OR &quot;chemoprevention&quot;[All Fields]) OR (&quot;chloroquine&quot;[MeSH Terms] OR &quot;chloroquine&quot;[All Fields]) OR (&quot;pyrimethamine&quot;[MeSH Terms] OR &quot;pyrimethamine&quot;[All Fields]) OR (&quot;proguanil&quot;[MeSH Terms] OR &quot;proguanil&quot;[All Fields]) OR (Pyrimethamine-dapsone[All Fields]) OR (&quot;fanasil, pyrimethamine drug combination&quot;[Supplementary Concept] OR &quot;fanasil, pyrimethamine drug combination&quot;[All Fields] OR &quot;sulfadoxine pyrimethamine&quot;[All Fields]) OR (&quot;mefloquine&quot;[MeSH Terms] OR &quot;mefloquine&quot;[All Fields]) AND ([Publication Type] OR &quot;randomized controlled trials as topic&quot;[MeSH Terms] OR &quot;randomized controlled trial&quot;[All Fields] OR &quot;randomised controlled trial&quot;[All Fields]) AND (parasitaemia[All Fields] OR &quot;parasites&quot;[MeSH Terms] OR &quot;parasites&quot;[All Fields] OR &quot;parasite&quot;[All Fields]) Once you are satisfied with your results, you could choose to apply the same search to another database. This might be worth the effort if your topic crosses disciplinary boundaries, like economics and health. Best to check with a research librarian. Screening results Even the best search queries return some duds, so the next step is screening. We can return to Radeva-Petrova et al. (2014) to see what a thorough approach looks like. You would likely take some shortcuts for a regular literature review. Typically systematic review searches will return hundreds or thousands of potential hits, so a study team will screen titles and abstracts to exclude obvious mistakes. When beginning this process, it’s common to have team members screen some of the same records to establish reliability, a concept that we will discuss in more depth in the chapter on measurement. Basically, you want to know that everyone screening records would make the same inclusion/exclusion decision. The Radeva-Petrova et al. (2014) search strategy turned up 179 unique records, and the authors excluded 126 of these records after screening the abstracts. The excluded studies did not meet certain pre-defined criteria. For instance, the authors only wanted to include studies using RCTs and quasi-experimental designs. This left the team with 53 studies that required a full-text review. Only 17 of the 53 studies still met eligibility criteria after this review.19 Supplemental searches It is customary in a systematic review–and helpful in general reviews—to augment database searches with reference reviews and hand searches to ensure that no key references were missed in the database query. A reference review is nothing more than a scan of an eligible article’s bibliography. In a hand search, you would go to the website of journals that published the eligible articles and scan the tables of contents for each issue published during the search window. If you find that either supplemental method turns up a lot of new results, it could make sense to revise your systematic review search strategy to be more comprehensive. Extracting data Depending on your objectives you might choose to systematically extract data from each study—key facts related to study design, methods, and results. Or you might take a shorter path and create an annotated bibliography. If you need to be more systematic—an essential requirement for a capital “S” Systematic review—then you need to design a data extraction strategy. Your PICO research question can be a helpful guide to identifying the minimum data you should extract. Returning to Radeva-Petrova et al. (2014): Among pregnant women living in malaria-endemic areas, is chemoprevention more effective than a placebo at preventing parasitaemia? Some possibilities include: study setting/population sample size sample demographics, including parity study design intervention details, such as specific medication and dose primary outcome (e.g., parasitaemia) effect size There are numerous software options for storing your extracted data, but you’ll likely find that a simple spreadsheet with rows of studies and columns of study variables will work just fine. Lots of teams use this approach for big systematic reviews, so it will probably serve you well for something more modest. 2.3 For the Love of Everything Holy Use a Reference Manager Even if you chose to ignore everything I’ve written up to this point, do yourself a favor and use a program for managing references. I’m amazed every year when I learn that students on the precipice of graduation manually type and format their in-text citations and bibliographies. What a waste of time! There are several reference managers you might consider. I’ll mention one because it is free and open-source: Zotero. The concept of “free” does not need much explanation, but students often have several free options that are not really free. A good example is a program like EndNote. A university might make this program a free download for enrolled students, but the license expires upon graduation or soon becomes obsolete without a paid upgrade. Additionally, in global health it’s common to work with colleagues who do not have access to a program like EndNote, which makes collaboration challenging. For these reasons, I highly recommend a program like Zotero that is free to use and open to improve. A tutorial is beyond the scope of this chapter, but it’s worth mentioning some features that are common to many reference managers: Easy importing of references from databases like PubMed. Go from your search results to reference manager in seconds. Automatic retrieval of full-text PDF. Sync PDFs in collection to tablets and phones Connections to word processing software to make inserting references in papers a snap. Automatic creation of bibliographies based on works cited. Push button reformatting of in-text citations and references to different styles, such as APA and Harvard. Shared collections with automatic syncing via the cloud to facilitate collaboration. Easy export of references for migration to just about any other reference manager. So next time you see someone typing references and complaining about APA formatting, open your laptop and run your reference manager. Be prepared to offer tissues. Your colleague will either cry for joy or deep despair about wasted effort. You’ll feel good about yourself regardless. References "],
["critical.html", "3 Critical Appraisal 3.1 Be Skeptical of News Reports and Press Releases 3.2 Peer-Reviewed Does Not Mean Correct 3.3 How to be a Good Consumer of Research Additional Resources", " 3 Critical Appraisal Scholars in every discipline have their own ways of reading and evaluating the literature. In medicine, this process is called critical appraisal and it’s part of a larger approach called evidence-based medicine or, more generally, evidence-based practice (EBP). In EBM, the goal is to integrate the best available evidence with clinical judgment and context, such as a patient’s preferences and values. Sackett (1996) offers a more formal definition: The conscientious, explicit and judicious use of current best evidence in making decisions about the care of the individual patient. It means integrating individual clinical expertise with the best available external clinical evidence from systematic research. There are several steps in EBM. We covered 2 and 3 in the previous chapter. ASSESS the patient: What is the clinical problem? ASK the question: Develop a clinical question using tools like PICO that we introduced in the previous chapter. ACQUIRE the evidence: Search the literature or find systematic reviews or meta-analyses. APPRAISE the evidence: Evaluate the quality and applicability of the research evidence. APPLY this to the patient’s case: Combine the best empirical evidence with clinical judgement and the patient’s preferences. EBM is focused on patient care, but the approach has been extended to evidence-based public health (Brownson, Fielding, and Maylahn 2009) and evidence-based global health policy (Yamey and Feachem 2011). Just as in EBM, the aim of these two new EB__’s is to adopt policies and programs that have been shown to save lives and improve health at scale. But before policymakers can make evidence-based decisions, the scientific community must evaluate the strength of the evidence. So let’s dive into step 4, critical appraisal. 3.1 Be Skeptical of News Reports and Press Releases Much of what we learn about scientific results from the media comes in the form of clickbait, such as this article in Discover Magazine titled “Want to avoid malaria? Just wear a chicken.” Would you be surprised if I told you that the study did not actually require people to wear chickens?20 Are you worried about getting malaria? Well, according to this study, you might be able to avoid it by carrying a chicken everywhere you go. These findings…give “tastes like chicken” a whole new meaning! Despite the outlandish title, this news report got it mostly right, so it’s better than most. If you turn on the news or read a university press release, you’ll often find summaries and claims that go far beyond the conclusions of the original article. This is because most studies give us a small glimpse at the “truth”, but the measured and careful language of scientific articles does not always capture the attention of the public. Part of the problem is also that good science writers are hard to come by. One of the best is Ben Goldacre, a British psychiatrist who runs the EMB Data Lab at the Centre for Evidence-Based Medicine at the University of Oxford. He wrote the Guardian’s “Bad Science” column for a decade, and published a great book with the same title. In 2011 he published a paper with some colleagues on the reliability of health reporting. Here’s how he described that work in the Guardian: Here’s what we did. First, we needed a representative, unbiased sample of news stories, so we bought every one of the top 10 bestselling UK newspapers, every day for one week…We went through these to pull out every story with any kind of health claim, about any kind of food or drink, which could be interpreted by a reader as health advice. So “red wine causes breast cancer” was in, but “oranges contain vitamin C” was not. Then the evidence for every claim was checked…Finally, to produce data for spotting patterns, the evidence for each claim was graded using two standard systems for categorising the strength of evidence. Here’s what we found: 111 health claims were made in UK newspapers over one week. The vast majority of these claims were only supported by evidence categorised as “insufficient” (62%). After that, 10% were “possible”, 12% were “probable”, and in only 15% was the evidence “convincing”. Yikes! 3.2 Peer-Reviewed Does Not Mean Correct Journalists and communications professionals can and do make mistakes in summarizing and interpreting scientific findings, but sometimes the problem is further upstream with the study authors. But how can published research be flawed, you ask? It was peer-reviewed! Peer review is an important component of the scientific process, but it is not a guarantee of “truth” or a certification of the results. So what is peer review? 3.2.1 Getting past the gatekeepers Let’s say you just completed what you think is a fascinating new study that upends years of conventional thinking on your research question. You could issue a press release and tell the world, but most scientists would reserve judgement or consider your results preliminary pending peer review. They would expect you to write a manuscript detailing your research design, data, methods, and results, and then submit this manuscript to an academic or scholarly journal. Typically, your submission would be screened by the journal’s editor, a role often filled by a senior scientist in your field. If the editor thinks that your paper is free of obvious fatal flaws and will be of interest the journal’s readership, then the editor might assign it to an associate editor with some expertise on your topic to manage the peer review process. 3.2.2 Who is a peer? The associate editor will then attempt to find 3 or more scholars in your field—your peers—to review the paper and comment on its merits. Some journals give you the option to recommend reviewers who might be a good fit and to request that certain colleagues are not considered. The editorial team does not need to respect your wishes, but finding appropriate reviewers is a challenge and you can help by suggesting scholars who are qualified to evaluate your work. So a “peer” can be: someone at your level, more junior, or more senior someone who shares the same conceptual framework regarding your topic of study, or someone who takes a different view entirely someone who works on a parallel topic, or someone who is a direct “competitor” someone who is a topic expert, or, when it’s hard to find the right person, someone who does not have much background at all someone who is a technical expert on your methods, or someone who does not know the first thing about your chosen analytical approach You’ll probably never know. Most journals use a blind review process by which you don’t know who accepts the editor’s request to review your paper, and the reviewers are not informed of your identity. At least that’s the idea. Sometimes reviewers give hints about their identity by recommending that you cite a lot of their own work. And sometimes it’s easy to determine your identity as the author because your current work builds on your previous studies or you’ve already presented the work at scientific conferences. 3.2.3 What happens during the review process? Once your paper arrives on a reviewer’s desk, he or she will take a few weeks (or months!) to recommend that your paper be rejected or accepted with no, minor, or major revisions. Some reviewers enumerate your perceived flaws in painstaking detail. Others give high-level comments that might be too vague to be helpful to your or the editor. The editorial team reviews these reviews, and it’s up to them to make a decision. Most academics are happy to get a “revise and resubmit” letter (aka, “R&amp;R”). The editor will usually give some indication that a revised paper would have a good chance of publication, but it’s not a guarantee. Sometimes the revised paper will go back out for further review, but the editor can also make the decision to accept the revision without additional input. The editor has a tough task because it’s often the case that reviewers take different positions on your submission. As Smith (2006) suggested, these recommendations can be direct opposites: Reviewer A: `I found this paper an extremely muddled paper with a large number of deficits’ Reviewer B: `It is written in a clear style and would be understood by any reader’. So peer review is just like course evaluations! 3.2.4 What does NOT happen during the review process? A critical thing to note, however, is that reviewers almost never have access to your data or analysis code. They base their decisions on what you said you did (your methods), what you said you found (your results), and what you said it all means (your discussion). You have to describe your data sources, but no one is checking your work. So even if reviewers find possible flaws in your logic, analysis mistakes and fraud go largely unchecked.21 This lack of verification is why it is wrong for people to conclude that published in a peer-reviewed journal means correct. Journalists can harbor this belief, and defensive authors sometimes promote it when challenged on their study’s findings. If it were true that published==correct, then we’d have no need for corrigendum and retractions—and the website Retraction Watch would be empty. 3.3 How to be a Good Consumer of Research Here’s a nice framework for how to be a good peer reviewer (aka, referee) that is a good starting point for thinking about how to be a good consumer of research more generally. In this guide, Leek describes a scientific paper as consisting of four parts.22 I take the liberty of collapsing methodologies and data, as well as adding the Introduction. An introduction that frames the research question A set of methodologies and a description of data A set of results A set of claims Leek offers a helpful recommendation about how to approach a new paper: Your prior belief about [2-3] should start with the assumption that the scientists in question are reasonable people who made efforts to be correct, thorough, transparent, and not exaggerate. This book focuses mainly on how to read and write sections 1 and 2. I think you’ll gain new insight into how to evaluate research results and claims if you make it to the end, but it’s probably safe to say that you’ll need more background in analysis to feel confident in your ability to critique findings and plan your own analysis. 3.3.1 Introduction A good Introduction will explain the aim of the paper and put the research question in context.23 In public health and medicine, this section will often be very short compared to what you’ll find in other disciplines like economics. As a reader, you want to focus on understanding the research question. If you are familiar with the research area, you might also read the Introduction with a critical eye toward the literature reviewed. Did the authors miss any key references that could signal that they are unaware of developments in the field?24 3.3.2 Method A good Method section will provide enough information to let the reader attempt to replicate the findings in a new study. Journal space constraints make this challenging, so you’ll often find that authors post supplemental materials online that give additional details.25 Even with supplemental materials, however, it would be common to need to contact the author for additional details and materials if you really wanted to attempt a replication. The organization of the Method section will vary by discipline, but you should expect to find some information about the research design, subjects, materials or measures, data sources and procedures, and analysis strategy. The Equator Network, which awkwardly stands for “Enhancing the QUAlity and Transparency Of health Research”, is a good resource for understanding modern reporting standards. If you are preparing your own manuscript, most journals will expect you to include all of the information outlined in the checklist that’s relevant for your research design. If you are reviewing an article, you can do your part to promote comprehensive reporting by referring authors to these checklists. Include the completed checklist as an appendix with your article submission to head off reviewers who will complain about missing information that you definitely included on page 5, line 20 thank you very much. Is the research design well-suited to answer the research question? This book will introduce you to common research designs in global health. What you should know at this point in your reading is that there are many different designs that could potentially answer most research questions, but not all designs are created equal. And it’s not always possible to use the design that would produce the highest quality evidence. Figure 3.1: Levels of evidence A graphic like this is commonly used in the EBM literature to convey the point that research designs are not created equal. The meta-analyses and systematic reviews that you read about in Chapter 2 are ‘studies of studies’ and they sit atop the evidence hierarchy. They enjoy this status because they synthesize the best available evidence. If you accept that no one study is the final word on a research question, then it will make sense that a meta-analysis that pools together results and accounts for variable study quality could potentially give you a better answer than any one study. Is there a risk of bias and confounding? Some study designs are better than others in theory because of their ability to address potential bias when conducted properly. As we discussed in Chapter 1, the goal of scientific research is inference and we must live with some error and uncertainty. As a consumer of research, you have to accept this as fact and assess the extent to which a study’s design and methods might lead us away from the “truth”. The Cochrane Handbook for Systematic Reviews (2011) cautions us to pay attention to design features (e.g., how participants were selected) rather than labels (e.g., cohort study) because such labels are broad categories. Therefore, don’t rely too much on the evidence hierarchy shown above. These rankings reflect ideals. It’s possible to have a poorly designed or implemented RCT. The evidence from such a flawed study will not necessarily be better than the evidence from a non-randomized study just because it carries the label “randomized”. Error comes in two flavors: random and systematic. Random error adds noise (aka, variability) to your data, but it does not affect the average. For instance, I might step on a scale and see that I weigh 185.12. I step off and back on, and this time I weigh 185.13.26 This is random error that results from the limitations of my scale. If I keep taking measurements, this random error will balance out. Random means that the readings won’t be systematically too high or too low. You’ve probably already guessed that systematic error is not random. Systematic error is also known as bias and represents a deviation from the “truth”. Let’s imagine that my scale is broken and I don’t really weigh 185. I weigh 200. I can worry about the imprecise measurements of 185.12 and 185.13 all day, but I’d be missing the bigger problem that my scale is systematically reading the wrong weight. I can keep taking measurements over and over, but my scale is just wrong. If my goal is 186, I would come to the wrong conclusion that I can stop dieting! You can estimate random error (as we’ll discuss in Chapter 7), but you typically don’t know the extent to which bias affects your study results. For this reason, we often frame this as a “risk of bias”. In a non-randomized design, the biggest risk of bias comes from potential selection bias (Higgins and Green 2011). Selection bias can take different forms. In the context of intervention research, selection bias represents pre-treatment (aka, baseline) differences between study groups. For instance, Webster et al. (2003) conducted a case-control study—a non-randomized, or observational study design that we’ll discuss more in Chapter 10—in Eastern Afghanistan to study the efficacy of bednets as a tool for preventing malaria. Patients who presented at the study clinic with a fever were tested for malaria. Those who tested positive were classified as “cases”, and the rest were classified as “controls”. The researchers asked cases and controls about their bednet use, education, income, and several other characteristics. Then they compared bednet users and non-users on their odds of malaria (i.e., being classified as cases). Webster et al. (2003) wanted to look at potential selection effects with this particular research design, so they also examined patients’ use of chloroquine prior to attending the clinic. If a patient was classified as a control (negative blood film) but tested positive for chloroquine, this would indicate that the patient received treatment for malaria prior to arriving at the clinic, meaning they really should have been classified as a case. To determine if this misclassification of cases as controls could introduce selection bias, the authors looked at chloroquine use in bednet users and non-users. They found that the use of chloroquine prior to clinic testing was LESS common among patients who reported using bednets compared to non-users. If chloroquine use was less common among bednet users, it would underestimate the estimated effect of bednets. Consider the following example. Figure 3.2: Selection bias Panels A and B show cases (those who tested positive for malaria) and controls by their reported bednet usage. In Panel A, there are 4 patients who are misclassified as controls, meaning that they tested negative for malaria but only because they treated themselves with chloroquine prior to the test. You can see that chloroquine use is less common among net users. Still in Panel A, we see that the odds of malaria (cases) among bednet users is 12/30 and the odds of malaria among non-users is 12/18. This is an odds ratio of 0.60, suggesting that bednets protect against malaria (a value of 1 would indicate no effect). However, Panel B shows that this effect might be an underestimate. If we move the misclassified control patients to the case group where they belong, the odds change. Now the odds of malaria among bednet users is 13/30 and the odds among non-users is 15/18. This is an odds ratio of 0.52, suggesting an even greater protective effect. In Panel A, the effect was biased toward the null, meaning that the effect looked smaller than it probably is in reality. This bias results in confounding, and we would call chloroquine use a confounding variable. Confounding variables are correlated with both the “treatment” (i.e., bednet use) and the outcome (i.e., malaria). As we’ll explore later, an experimental design typically overcomes this risk of bias and confounding because bednet ownership can be randomly assigned. If the sample size is large enough, we’d expect chloroquine use to be equally distributed between the bednet and non-bednet groups. The key word here is “typically”. Things can still go wrong in an experimental design that result in a risk of bias. For this reason, every Cochrane systematic review assess several types of known risks of bias in RCTs (Higgins and Green 2011): selection bias performance bias detection bias attrition bias reporting bias We’ll discuss these sources of bias more in Chapter 12, but the takeaway should be that every study has a potential for bias and, as a reviewer or general research consumer, you should assess the risks of bias that might challenge the validity of the results. As you’ll see later, this type of validity—are the study results “correct”?—is typically referred to as internal validity (Higgins and Green 2011). At the end of this chapter you’ll read about another dimension of validity called external validity. Who (or what) was the subject of study and how were these subjects recruited and/or selected? Studies of human subjects typically have a subsection of the Method section that describe participant selection and recruitment. What made someone eligible or ineligible to participate? Who was excluded, intentionally or not? These details help to define the population of interest and will inform the study’s generalizability, a concept we’ll discuss shortly. Once eligible participants were identified, how were they selected and recruited? Was this process random, or did the researchers invite who was available? As you’ll learn in Chapter 7, the method of sampling has implications for what inferences are possible about the population. What materials and/or measures were used in the course of the study? Almost every study uses some type of materials or measures. Diagnostic studies, for instance, evaluate a diagnostic test or a piece of hardware that analyzes the test samples. Environmental studies might use sophisticated instruments to take atmospheric measurements. Expect studies like these to provide specific details about the materials and equipment. Study variables also need to be precisely defined. For instance, hyperparasitemia describes a condition of many malaria parasites in the blood. But what constitutes “many”? The WHO defines it as “a parasite density &gt; 4% (~200,000/µL)” (WHO 2015). Does the study use this definition? Another one? In studies measuring social or psychological constructs such as anxiety, you’d expect to read about how this thing called “anxiety” is defined and measured. Is anxiety diagnosed by a psychiatrist (if so what is the basis for this diagnosis?) or is anxiety inferred from a participant’s self-reported symptoms on a checklist or screening instrument (if so, what are the questions and how is the instrument scored?)? We’ll dive into measurement issues in Chapter 6. How was the study conducted and how were the data collected? This part of a Method section should describe what happened after participants were recruited and enrolled. What happened first, second, third? If the study is observational, the procedures might be limited to data collection. Who collected the data, and how were they trained? Where were the data collected? For intervention studies, the procedures will describe how participants were randomized to study arms and what happened (or did not happen) in each arm. Were the participants, data collectors, and/or patients blind to the treatment assignment? How were the data analyzed? If the study uses a hypothesis-testing framework (and not all do), then you’ll find details about study hypotheses in the Introduction or Method section, depending on the journal. The Method section should also detail how the analysis will be carried out. For instance, if you are reading an intervention study, how was the effect size be estimated? Ordinary least squares regression? Logistic regression? The list goes on and on. When you are preparing your own manuscript, remember that the Method section is where you should define variables and specify your analysis. Your Results section should just get to the business of reporting the findings. There’s no need to re-explain your analysis. Was the study pre-registered and approved by an ethics board? The US Federal Policy for the Protection of Human Subjects (aka, the “Common Rule”) defines research as “a systematic investigation, including research development, testing and evaluation, designed to develop or contribute to generalizable knowledge…” If the research involves human subjects, it must be reviewed and approved by an Institutional Review Board before any subjects can be enrolled. Most studies fall under IRB oversight, but some might qualify as exempt. Figure 3.3: Is the human subjects research eligible for exemption?; Source: http://bit.ly/2brlbKR. Increasingly researchers are taking the additional step of registering a study protocol prior to the study launch in a clearinghouse like https://clinicaltrials.gov/. This is a requirement for investigations of drugs that are regulated by the FDA, and now it’s an expectation of many journals.27 Pre-registration does not ensure trustworthy results, but the practice is a welcome increase in research transparency. If the analysis described in an article deviates from the planned analysis, you would expect the authors to provide a compelling justification. Studies often measure a number of outcomes (sometimes in a number of different ways), and it’s easy to cherry-pick results and find something to present. Sometimes authors will actually deviate from the pre-registered protocol and present different results when the pre-registered plan does not work out. This is called outcome switching. Some medical journals don’t seem to care, but the COMPare Trials Project thinks they should. Figure 3.4: Is outcome switching a problem in medical trials?; Source: http://compare-trials.org/. 3.3.3 Results Can each finding be linked to data and procedures presented in the Methods Every finding in the Results section should be linked to a methodology and source of data documented in the Method section. Articles in medical journals are some of the shortest, so you might need to download supplemental materials posted online to get a clearer sense of what the authors did and found. Remember, a plot twist can be a useful literary device in a work of fiction. This advice does not extend to journal articles. Is the analysis correct? This can be a difficult question to answer as a new consumer of research. Without access to the data and any analysis code—still the norm for most publications—you can’t independently verify the results. Even if you did have access, some analyses are so complex that only people with extensive training feel qualified to question the results of published works. Thankfully you don’t need a degree in biostatistics to be a good consumer of research. You can get a long way by adopting some basic approaches to critical appraisal. Exhibit A: a Lancet article published by Pronyk et al. (2012) about the impact of the Millennium Villages Project (MVP) on child survival in rural sub-Saharan Africa. The MVP was founded by economist Jeffrey Sachs as a proof of his concept that extreme poverty could be solved, and the Millennium Development Goals met, with a big financial push. The basic idea behind a Millennium Village is to intervene across sectors simultaneously—water, sanitation, education, health, etc.—to give communities a chance to escape the poverty trap. Sachs and his colleagues published their first comprehensive report on the MVP in the Lancet with the stated aim to “assess progress towards the MDGs and child survival over the project’s first 3 years and compare these changes to local trends”. The authors examined child mortality rates across 9 Millennium Villages and concluded: The average annual rate of reduction of mortality in children younger than 5 years of age was three-times faster in Millennium Village sites than in the most recent 10-year national rural trends (7·8% vs 2·6%) When this article was published online, Bump et al. (2012) challenged the calculation of both of these figures and the resulting interpretation that the MVP had a large impact on child mortality. One of the authors of this criticism, Gabriel Demombynes, explained the errors in this post. First, Pronyk et al. (2012) annualized (aka, divided) the 21.7% cumulative decline in mortality by 3 for the number of years the intervention was active rather than by 4, the correct time window for this retrospective assessment of mortality. This correction reduces the annual rate of decline among Millennium Villages from a claim of 7.8% to an actual 5.4%. Second, Pronyk et al. (2012) compared their estimated annual decline after 2006 (7.8%) to the results of national surveys in MVP countries from 2001-10. A more appropriate comparison using all of the available post-2006 data suggests an average annual rate of decline of 6.4% across the 9 MVP countries. Figure 3.5: Correcting the MVP estimate of impact on child mortality; Source: http://bit.ly/2aGSk2m Bump et al. (2012) conclude: The above observations imply that a key finding of the paper—that child mortality fell at the treatment sites at triple the nationwide rural background rate—is incorrect. Child mortality fell at 5·9% per year at the sites versus 6·4% per year on average across all areas of the countries in question (probably more in rural areas alone) according to the available data that most closely match the project period. This difference is not significant. Pronyk (2012) published a correction that was noted by Retraction Watch. 3.3.4 Discussion Is each claim linked to a finding presented in the Results? Each claim (e.g., the world is flat) should be supported by results that are reported in the paper (e.g., summary of altitude data). If you don’t find a link between a claim in the Discussion section with a finding in the Results section, you should begin to wonder if the author is “going beyond the data”. For instance, if I present results on the efficacy of a new treatment for malaria but do not present any data on cost, then it would be inappropriate for me to claim that the treatment is “cost-effective”. It’s legitimate to speculate a bit in the Discussion section based on documented findings, but authors should be careful to label all speculation as such—and these thought exercises should never find their way into the article’s Abstract. Is each claim justified? Once you establish that there is a link between a claim and a set of results, you want to make sure that the claim represents a correct interpretation of these findings. For instance, do the authors tell you that the results should not be interpreted as a causal relationship and then go on to recommend that we impose a tax on margarine in order to strengthen the American family? Figure 3.6: Divorce rate in Maine correlates with per capita consumption of margarine, r=0.99; Source: http://www.tylervigen.com/spurious-correlations Are the claims generalizable? Most [studies] are highly localized and paticularistic…Yet readers of [your study’s] results are rarely concerned with what happened in that particular, past, local study. Rather, they usually aim to learn either about theoretical constructs of interest or about a larger policy. That’s Shadish et al. (2003) writing about the importance of generalizability of research findings and claims. When a study is so highly localized that the results are unlikely to generalize to new people and places, we’d say that the study has low external validity. One approach to promoting generalizability is to use formal probability sampling. We’ll cover this more in Chapter 7, but randomly sampling participants from the population of interest is one way to increase the external validity of a study. For instance, Wanzira et al. (2016) analyzed data from the 2014 Uganda Malaria Indicator Survey, a large national survey, and found that women who knew that sulfadoxine/pyrimethamine (SP) is a medication used to prevent malaria during pregnancy had greater odds of taking at least two doses as compared to women who did not have this knowledge. Since the UMIS is nationally representative, we could assume that the results could apply to Ugandan women who did not participate in the study. Would the results generalize to women in Tanzania? Yes, one could make an argument that they would. Would the results generalize to women in France? No, probably not. For one, malaria is not an issue there. Are the claims put in context? A good Discussion section will put the study’s findings in context by suggesting how the study adds to the literature. Do the results replicate or support other work? Or do the findings run contrary to other published studies? What are the limitations? No study is perfect, so there’s no need to pretend that yours is any different. In addition to knowing how the results fit into the bigger research landscape, it’s also important for readers to understand potential limitations of your design and method. Additional Resources Critical appraisal worksheets from the Centre for Evidence-Based Medicine BMJ Series on “How to Read a Paper” Critical appraisal resources from Duke Medicine References "],
["causeeffect.html", "4 Cause and Effect", " 4 Cause and Effect "],
["references.html", "5 References", " 5 References "]
]
